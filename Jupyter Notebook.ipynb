{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetExtractor():\n",
    "\n",
    "    def __init__(self, APP_KEY, APP_SECRET):\n",
    "        from twython import Twython\n",
    "        self.twitter = Twython(APP_KEY, APP_SECRET)\n",
    "\n",
    "    def getName(self):\n",
    "        self.username = input(\"Enter screen_name?\")\n",
    "\n",
    "    def getTimeline(self,screen_name,count, max_id=None):\n",
    "        if(max_id == None):\n",
    "            return self.twitter.get_user_timeline(\n",
    "                screen_name=screen_name, count=count)\n",
    "        else:\n",
    "            return self.twitter.get_user_timeline(\n",
    "                screen_name=screen_name, count=count, max_id=max_id)\n",
    "\n",
    "    def getLastID(self, user_timeline):\n",
    "        return user_timeline[0]['id']-1\n",
    "\n",
    "    def getAllTweets(self,screen_name):\n",
    "        self.user_timeline = self.getTimeline(screen_name, 1)\n",
    "        for _i in range(16):\n",
    "            new200tweets = self.getTimeline(screen_name, 200, self.getLastID(self.user_timeline))\n",
    "            self.user_timeline.extend(new200tweets)\n",
    "        return self.user_timeline\n",
    "    \n",
    "    def extractTweetsText(self,user_timeline):\n",
    "        return [item[\"text\"] for item in user_timeline]\n",
    "\n",
    "\n",
    "    def extractTweetsTextWithRef(self, user_timeline):\n",
    "        return [{\"text\":item[\"text\"],\"id_str\" : item[\"id_str\"]} for item in user_timeline]\n",
    "\n",
    "\n",
    "\n",
    "    def writeToFile(self,user_timeline):\n",
    "        import codecs\n",
    "        file = codecs.open(\"output.txt\", \"w\", \"utf-8\")\n",
    "        file.write(user_timeline)\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What username?mahdi_raf\n"
     ]
    }
   ],
   "source": [
    "from Config import *\n",
    "tweetExtractor = TweetExtractor(APP_KEY, APP_SECRET)\n",
    "tweets_list = tweetExtractor.extractTweetsTextWithRef(tweets)\n",
    "\n",
    "\n",
    "def getAllUsrTweets():\n",
    "    username = input(\"What username?\")\n",
    "    tweets = tweetExtractor.getAllTweets(username)\n",
    "    return tweets\n",
    "\n",
    "\n",
    "tweets = getAllUsrTweets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3201\n",
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'extended_entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))\n",
    "print((tweets[0]).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitiveWords = [\"جمهوری\", \"ج.ا\", \"اسلامی\", \"ایران\", \"مرگ\", \"جاعش\", \"خامنه\", \"احمدی نژاد\",\n",
    "                  \"روحانی\", \"@azarijahromi\", \"اینا\", \"مجلس\", \"قوه قضاییه\", \"رئیس\", \"آخوند\", \"شاه \", \"حجاب\", \"آمریکا\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "file = codecs.open(\"output.html\", \"w\", \"utf-8\")\n",
    "file.write(\"<div style='direction: rtl;'>\")\n",
    "for i in range(len(tweets_list)):\n",
    "    foundWords = []\n",
    "    for j in range(len(sensitiveWords)):\n",
    "        if(len(sensitiveWords[j]) == 0):\n",
    "            continue\n",
    "        if tweets_list[i][\"text\"].find(sensitiveWords[j]) > -1:\n",
    "            foundWords.append(sensitiveWords[j])\n",
    "    if len(foundWords)>0:\n",
    "        file.write(\"<p><a target='_blank' href='https://twitter.com/i/web/status/\" + tweets_list[i][\"id_str\"] +\"'>\"+tweets_list[i][\"text\"]+\"</a>\")\n",
    "        file.write(\"       \"+' '.join([str(elem) for elem in foundWords])+\"</p>\")\n",
    "        file.write(\"<br>\")\n",
    "\n",
    "file.write(\"</div>\")\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
